{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aeb5e9db",
   "metadata": {},
   "source": [
    "# Fine-tune ViT for Chest X-ray Classification (Local, Feature Extraction)\n",
    "\n",
    "This notebook fine-tunes a Vision Transformer (ViT) on the Chest X-ray dataset (Pneumonia vs Normal) using your local dataset at `mediscan/data/chest_xray`. Only the classification head is trained (feature extraction)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e078bc75",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies\n",
    "\n",
    "Install Hugging Face Transformers, Datasets, and other requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8fddb92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\tejas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.51.3)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: datasets in c:\\users\\tejas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.6.0)\n",
      "Requirement already satisfied: pillow in c:\\users\\tejas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (10.0.1)\n",
      "Requirement already satisfied: torch in c:\\users\\tejas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\tejas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.22.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\tejas\\appdata\\roaming\\python\\python310\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\tejas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.31.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\tejas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\tejas\\appdata\\roaming\\python\\python310\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\tejas\\appdata\\roaming\\python\\python310\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\tejas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\tejas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\tejas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\tejas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\tejas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\tejas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\tejas\\appdata\\roaming\\python\\python310\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\tejas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\tejas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\tejas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (2.0.3)\n",
      "Requirement already satisfied: xxhash in c:\\users\\tejas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\tejas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\tejas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.18)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\tejas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\tejas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\tejas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\tejas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\tejas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\tejas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\tejas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\tejas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\tejas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\tejas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\tejas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\tejas\\appdata\\roaming\\python\\python310\\site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\tejas\\appdata\\roaming\\python\\python310\\site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\tejas\\appdata\\roaming\\python\\python310\\site-packages (from requests->transformers) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tejas\\appdata\\roaming\\python\\python310\\site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\tejas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\tejas\\appdata\\roaming\\python\\python310\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\tejas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\tejas\\appdata\\roaming\\python\\python310\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\tejas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\tejas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\tejas\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers datasets pillow torch torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc92bcf",
   "metadata": {},
   "source": [
    "## 2. Set Dataset Paths\n",
    "\n",
    "Set the correct local paths for your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b43d7a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dir: C:\\Users\\Tejas\\OneDrive\\Desktop\\MedIntuit\\mediscan\\data\\chest_xray\\train\n",
      "Val dir: C:\\Users\\Tejas\\OneDrive\\Desktop\\MedIntuit\\mediscan\\data\\chest_xray\\val\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "base_dir = r\"C:\\Users\\Tejas\\OneDrive\\Desktop\\MedIntuit\\mediscan\\data\\chest_xray\"\n",
    "train_path = r\"C:\\Users\\Tejas\\OneDrive\\Desktop\\MedIntuit\\mediscan\\data\\chest_xray\\train\"\n",
    "val_path = r\"C:\\Users\\Tejas\\OneDrive\\Desktop\\MedIntuit\\mediscan\\data\\chest_xray\\val\"\n",
    "print(\"Train dir:\", train_path)\n",
    "print(\"Val dir:\", val_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81da2fb8",
   "metadata": {},
   "source": [
    "## 3. Load Dataset\n",
    "\n",
    "Load the train and validation splits using Hugging Face Datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9d4712e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample train_dataset[0]: {'image': <PIL.JpegImagePlugin.JpegImageFile image mode=L size=2090x1858 at 0x148C9476DD0>, 'label': 0}\n",
      "train_dataset features: {'image': Image(mode=None, decode=True, id=None), 'label': ClassLabel(names=['NORMAL', 'PNEUMONIA'], id=None)}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "train_dataset = load_dataset('imagefolder', data_dir=train_path, split='train')\n",
    "val_dataset = load_dataset('imagefolder', data_dir=val_path, split='train')\n",
    "\n",
    "print(\"Sample train_dataset[0]:\", train_dataset[0])\n",
    "print(\"train_dataset features:\", train_dataset.features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec59603",
   "metadata": {},
   "source": [
    "## 4. Prepare Labels\n",
    "\n",
    "Get class names and label mappings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "698bfad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: ['NORMAL', 'PNEUMONIA']\n"
     ]
    }
   ],
   "source": [
    "labels = train_dataset.features['label'].names\n",
    "id2label = {i: label for i, label in enumerate(labels)}\n",
    "label2id = {label: i for i, label in enumerate(labels)}\n",
    "\n",
    "print(\"Labels:\", labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455c78f3",
   "metadata": {},
   "source": [
    "## 5. Ensure All Images Are RGB\n",
    "\n",
    "Convert all grayscale images to RGB before training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd2536e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def ensure_rgb(img):\n",
    "    if isinstance(img, Image.Image):\n",
    "        if img.mode != \"RGB\":\n",
    "            return img.convert(\"RGB\")\n",
    "        return img\n",
    "    if isinstance(img, np.ndarray):\n",
    "        if img.ndim == 2:  # grayscale\n",
    "            return Image.fromarray(img).convert(\"RGB\")\n",
    "        elif img.ndim == 3 and img.shape[2] == 1:\n",
    "            return Image.fromarray(img.squeeze(-1)).convert(\"RGB\")\n",
    "        elif img.ndim == 3 and img.shape[2] == 3:\n",
    "            return Image.fromarray(img)\n",
    "    return img\n",
    "\n",
    "def fix_dataset_rgb(dataset):\n",
    "    for i in range(len(dataset)):\n",
    "        img = dataset[i]['image']\n",
    "        dataset[i]['image'] = ensure_rgb(img)\n",
    "\n",
    "fix_dataset_rgb(train_dataset)\n",
    "fix_dataset_rgb(val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc217b0",
   "metadata": {},
   "source": [
    "## 6. Load Pretrained ViT and Freeze Base\n",
    "\n",
    "Load the ViT model and processor, and freeze the base model for head-only training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57076fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Tejas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "import torch\n",
    "\n",
    "model_name = \"google/vit-base-patch16-224\"\n",
    "processor = AutoImageProcessor.from_pretrained(model_name)\n",
    "model = AutoModelForImageClassification.from_pretrained(model_name)\n",
    "\n",
    "# Replace the classification head for your number of classes\n",
    "model.classifier = torch.nn.Linear(model.classifier.in_features, len(labels))\n",
    "model.config.num_labels = len(labels)\n",
    "model.config.id2label = id2label\n",
    "model.config.label2id = label2id\n",
    "\n",
    "# Freeze base ViT parameters\n",
    "for param in model.vit.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50040e04",
   "metadata": {},
   "source": [
    "## 7. Preprocessing Function\n",
    "\n",
    "Define a transform to preprocess images for ViT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "164c004f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(example_batch):\n",
    "    inputs = processor(images=example_batch['image'], return_tensors='pt')\n",
    "    inputs['label'] = example_batch['label']\n",
    "    return inputs\n",
    "\n",
    "train_dataset.set_transform(transform)\n",
    "val_dataset.set_transform(transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18cbfa3",
   "metadata": {},
   "source": [
    "## 8. Training Arguments\n",
    "\n",
    "Set up Hugging Face Trainer arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fad4dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install accelerate package for faster training\n",
    "%pip install accelerate>=0.26.0 transformers datasets evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d355fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then import the necessary classes\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "# Now define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    learning_rate=2e-4,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5fa501f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train classes: ['NORMAL', 'PNEUMONIA']\n",
      "Found 1341 images in NORMAL\n",
      "Found 3875 images in PNEUMONIA\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Use the existing train_path variable or construct it from base_dir\n",
    "train_path = os.path.join(base_dir, \"train\")\n",
    "print(\"Train classes:\", os.listdir(train_path))\n",
    "\n",
    "for cls in os.listdir(train_path):\n",
    "    cls_path = os.path.join(train_path, cls)\n",
    "    print(f\"Found {len(os.listdir(cls_path))} images in {cls}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c285a203",
   "metadata": {},
   "source": [
    "## 9. Train the Model\n",
    "\n",
    "Use Hugging Face Trainer to train only the classification head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c619fb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-4,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c6c4dc",
   "metadata": {},
   "source": [
    "## 10. Save Model\n",
    "\n",
    "Save the fine-tuned model and processor locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "39799848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./fine_tuned_model\\\\preprocessor_config.json']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"./fine_tuned_model\"\n",
    "model.save_pretrained(model_path)\n",
    "processor.save_pretrained(model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
